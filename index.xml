<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Greg Anderson</title>
    <link>https://gavlegoat.github.io/</link>
    <description>Recent content on Greg Anderson</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language><atom:link href="https://gavlegoat.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>CS342: Neural Networks</title>
      <link>https://gavlegoat.github.io/cs342/</link>
      <pubDate>Wed, 05 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://gavlegoat.github.io/cs342/</guid>
      <description>In this course, we discuss the basics of deep neural networks. We will look at different neural architectures, as well as how to train, tune, and test networks. We will cover both the theory and practice of deep learning, using hands-on implementations in PyTorch. We will then briefly look at a number of common applications of deep learning including computer vision, sequence modeling, deep reinforcement learning, and generative modeling. Over the course of the homework assignments, we will develop a vision system for a racing simulator, SuperTuxKart.</description>
    </item>
    
    <item>
      <title>Research</title>
      <link>https://gavlegoat.github.io/research/</link>
      <pubDate>Sun, 16 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://gavlegoat.github.io/research/</guid>
      <description>My research broadly covers the intersection of programming languages and machine learning. In particular, I am most interested in developing techniques for proving the safety of systems with machine learning components. My early work in this domain has focused on using abstraction refinement to prove local robustness properties (PLDI&#39;19). More recently I have worked on incorporating ideas from PL research to develop a framework for deep reinforcement learning with formally guaranteed safety (NeurIPS&#39;20).</description>
    </item>
    
    <item>
      <title>Publications</title>
      <link>https://gavlegoat.github.io/publications/</link>
      <pubDate>Fri, 14 Jun 2019 11:06:23 -0500</pubDate>
      
      <guid>https://gavlegoat.github.io/publications/</guid>
      <description>Neurosymbolic Reinforcement Learning with Formally Verified Exploration. Greg Anderson, Abhinav Verma, Isil Dillig, Swarat Chaudhuri. At NeurIPS &amp;lsquo;20. Tool available here.
Optimization and Abstraction: A Synergistic Approach for Analyzing Neural Network Robustness. Greg Anderson, Shankara Pailoor, Isil Dillig, and Swarat Chaudhuri. At PLDI&#39;19 (Distinguished Paper). Tool available here.
Learning Abstractions for Program Synthesis. Xinyu Wang, Greg Anderson, Isil Dillig, Ken McMillan. At CAV&#39;18.
Formal Analysis of the Compact Position Reporting Algorithm.</description>
    </item>
    
    <item>
      <title>About</title>
      <link>https://gavlegoat.github.io/about/</link>
      <pubDate>Fri, 14 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://gavlegoat.github.io/about/</guid>
      <description>I&amp;rsquo;m a 5thyear PhD student at UT Austin&amp;rsquo;s UToPiA and Trishul groups, advised by Isil Dillig and Swarat Chaudhuri. My research focuses on the intersection of program analysis and machine learning. Specifically, I&amp;rsquo;m interested in developing tools and techniques which can analyze machine learning systems to guarantee safety. Before joining the UToPiA group I received my BS in Computer Engineering and Mathematics from the University of Virginia.</description>
    </item>
    
  </channel>
</rss>
